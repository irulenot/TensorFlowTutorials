{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow session to run parts of the graph across a set of local and remote devices.\n",
    "\n",
    "Dataflow is a common programming model for parallel computing.\n",
    "\n",
    "*tf.Operation (node) and tf.Tensor (edge) objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tf.Graph contains two relevant kinds of information:\n",
    "\n",
    "1) Graph structure. The nodes and edges of the graph, indicating how individual operations are composed together, but not prescribing how they should be used. The graph structure is like assembly code: inspecting it can convey some useful information, but it does not contain all of the useful context that source code conveys.\n",
    "\n",
    "2) Graph collections. TensorFlow provides a general mechanism for storing collections of metadata in a tf.Graph. The tf.add_to_collection function enables you to associate a list of objects with a key (where tf.GraphKeys defines some of the standard keys), and tf.get_collection enables you to look up all objects associated with a key. Many parts of the TensorFlow library use this facility: for example, when you create a tf.Variable, it is added by default to collections representing \"global variables\" and \"trainable variables\". When you later come to create a tf.train.Saver or tf.train.Optimizer, the variables in these collections are used as the default arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow provides a default graph that is an implicit argument to all API functions in the same context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tf.Graph object defines a namespace for the tf.Operation objects it contains. TensorFlow automatically chooses a unique name for each operation in your graph, but giving operations descriptive names can make your program easier to read and debug. The TensorFlow API provides two ways to override the name of an operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n",
    "\n",
    "# Already-used names will be \"uniquified\".\n",
    "c_1 = tf.constant(2, name=\"c\")  # => operation named \"c_1\"\n",
    "\n",
    "# Name scopes add a prefix to all operations created in the same context.\n",
    "with tf.name_scope(\"outer\"):\n",
    "  c_2 = tf.constant(2, name=\"c\")  # => operation named \"outer/c\"\n",
    "\n",
    "  # Name scopes nest like paths in a hierarchical file system.\n",
    "  with tf.name_scope(\"inner\"):\n",
    "    c_3 = tf.constant(3, name=\"c\")  # => operation named \"outer/inner/c\"\n",
    "\n",
    "  # Exiting a name scope context will return to the previous prefix.\n",
    "  c_4 = tf.constant(4, name=\"c\")  # => operation named \"outer/c_1\"\n",
    "\n",
    "  # Already-used name scopes will be \"uniquified\".\n",
    "  with tf.name_scope(\"inner\"):\n",
    "    c_5 = tf.constant(5, name=\"c\")  # => operation named \"outer/inner_1/c\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf.convert_to_tensor: Converts the given value to a Tensor.\n",
    "\n",
    "This function converts Python objects of various types to Tensor objects. It accepts Tensor objects, numpy arrays, Python lists, and Python scalars. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The following calls are equivalent.\n",
    "value_1 = tf.convert_to_tensor(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\n",
    "value_2 = tf.convert_to_tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "value_3 = tf.convert_to_tensor(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow uses the tf.Session class to represent a connection between the client program---typically a Python program, although a similar interface is available in other languages---and the C++ runtime. A tf.Session object provides access to devices in the local machine, and remote devices using the distributed TensorFlow runtime. It also caches information about your tf.Graph so that you can efficiently run the same computation multiple times.\n",
    "\n",
    "Since a tf.Session owns physical resources (such as GPUs and network connections), it is typically used as a context manager (in a with block) that automatically closes the session when you exit the block. It is also possible to create a session without using a with block, but you should explicitly call tf.Session.close when you are finished with it to free the resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Session.run requires you to specify a list of fetches, which determine the return values, and may be a tf.Operation, a tf.Tensor, or a tensor-like type such as tf.Variable. These fetches determine what subgraph of the overall tf.Graph must be executed to produce the result: this is the subgraph that contains all operations named in the fetch list, plus all operations whose outputs are used to compute the value of the fetches. For example, the following code fragment shows how different arguments to tf.Session.run cause different subgraphs to be executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.7177869e-13 1.0000000e+00]\n",
      " [8.9923143e-01 1.0076861e-01]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0]])\n",
    "w = tf.Variable(tf.random_uniform([2, 2]))\n",
    "y = tf.matmul(x, w)\n",
    "output = tf.nn.softmax(y)\n",
    "init_op = w.initializer\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Run the initializer on `w`.\n",
    "  sess.run(init_op)\n",
    "\n",
    "  # Evaluate `output`. `sess.run(output)` will return a NumPy array containing\n",
    "  # the result of the computation.\n",
    "  print(sess.run(output))\n",
    "\n",
    "  # Evaluate `y` and `output`. Note that `y` will only be computed once, and its\n",
    "  # result used both to return `y_val` and as an input to the `tf.nn.softmax()`\n",
    "  # op. Both `y_val` and `output_val` will be NumPy arrays.\n",
    "  y_val, output_val = sess.run([y, output])\n",
    "\n",
    "#Basically you need to sess run dependent variables to get final output\n",
    "# and use with statement when useing a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[node {\n",
      "  name: \"MatMul_4/a\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\024B\\000\\000\\270\\301\\000\\000\\200?\\000\\000\\200@\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_4/shape\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\002\\000\\000\\000\\002\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_4/RandomUniform\"\n",
      "  op: \"RandomUniform\"\n",
      "  input: \"random_uniform_4/shape\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed2\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_4/mul\"\n",
      "  op: \"Snapshot\"\n",
      "  input: \"random_uniform_4/RandomUniform\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_4\"\n",
      "  op: \"Snapshot\"\n",
      "  input: \"random_uniform_4/mul\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"MatMul_4\"\n",
      "  op: \"MatMul\"\n",
      "  input: \"MatMul_4/a\"\n",
      "  input: \"random_uniform_4\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_a\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_b\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"_retval_MatMul_4_0_0\"\n",
      "  op: \"_Retval\"\n",
      "  input: \"MatMul_4\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"index\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "}\n",
      "versions {\n",
      "  producer: 26\n",
      "}\n",
      "]\n",
      "dev_stats {\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  node_stats {\n",
      "    node_name: \"_SOURCE\"\n",
      "    all_start_micros: 1526946981710699\n",
      "    op_start_rel_micros: 2\n",
      "    op_end_rel_micros: 2\n",
      "    all_end_rel_micros: 7\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    timeline_label: \"_SOURCE = NoOp()\"\n",
      "    scheduled_micros: 1526946981710672\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"MatMul_4/a\"\n",
      "    all_start_micros: 1526946981710710\n",
      "    op_end_rel_micros: 6\n",
      "    all_end_rel_micros: 9\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 140411697308384\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"MatMul_4/a = Const()\"\n",
      "    scheduled_micros: 1526946981710706\n",
      "    memory_stats {\n",
      "      persistent_memory_size: 16\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_4/shape\"\n",
      "    all_start_micros: 1526946981710720\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 2\n",
      "    all_end_rel_micros: 4\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_INT32\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 8\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 140411745697120\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_4/shape = Const()\"\n",
      "    scheduled_micros: 1526946981710719\n",
      "    memory_stats {\n",
      "      persistent_memory_size: 8\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_4/RandomUniform\"\n",
      "    all_start_micros: 1526946981710726\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 10\n",
      "    all_end_rel_micros: 13\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "      total_bytes: 16\n",
      "      peak_bytes: 16\n",
      "      live_bytes: 16\n",
      "      allocation_records {\n",
      "        alloc_micros: 1526946981710731\n",
      "        alloc_bytes: 16\n",
      "      }\n",
      "      allocation_records {\n",
      "        alloc_micros: 1526946981710760\n",
      "        alloc_bytes: -16\n",
      "      }\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          has_single_reference: true\n",
      "          ptr: 140411745699584\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_4/RandomUniform = RandomUniform(random_uniform_4/shape)\"\n",
      "    scheduled_micros: 1526946981710724\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_4/mul\"\n",
      "    all_start_micros: 1526946981710740\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 3\n",
      "    all_end_rel_micros: 5\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          ptr: 140411745699584\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_4/mul = Snapshot(random_uniform_4/RandomUniform)\"\n",
      "    scheduled_micros: 1526946981710739\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_4\"\n",
      "    all_start_micros: 1526946981710746\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 1\n",
      "    all_end_rel_micros: 3\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          ptr: 140411745699584\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_4 = Snapshot(random_uniform_4/mul)\"\n",
      "    scheduled_micros: 1526946981710745\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"MatMul_4\"\n",
      "    all_start_micros: 1526946981710750\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 8\n",
      "    all_end_rel_micros: 11\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "      total_bytes: 16\n",
      "      peak_bytes: 16\n",
      "      live_bytes: 16\n",
      "      allocation_records {\n",
      "        alloc_micros: 1526946981710752\n",
      "        alloc_bytes: 16\n",
      "      }\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          has_single_reference: true\n",
      "          ptr: 140411745703584\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"MatMul_4 = MatMul(MatMul_4/a, random_uniform_4)\"\n",
      "    scheduled_micros: 1526946981710749\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"_retval_MatMul_4_0_0\"\n",
      "    all_start_micros: 1526946981710763\n",
      "    op_end_rel_micros: 1\n",
      "    all_end_rel_micros: 4\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    timeline_label: \"_retval_MatMul_4_0_0 = _Retval(MatMul_4)\"\n",
      "    scheduled_micros: 1526946981710761\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = tf.matmul([[37.0, -23.0], [1.0, 4.0]], tf.random_uniform([2, 2]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Define options for the `sess.run()` call.\n",
    "  options = tf.RunOptions()\n",
    "  options.output_partition_graphs = True\n",
    "  options.trace_level = tf.RunOptions.FULL_TRACE\n",
    "\n",
    "  # Define a container for the returned metadata.\n",
    "  metadata = tf.RunMetadata()\n",
    "\n",
    "  sess.run(y, options=options, run_metadata=metadata)\n",
    "\n",
    "  # Print the subgraphs that executed on each device.\n",
    "  print(metadata.partition_graphs)\n",
    "\n",
    "  # Print the timings of each operation that executed.\n",
    "  print(metadata.step_stats)\n",
    "\n",
    "\n",
    "# Can print out meta data per session's execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow includes tools that can help you to understand the code in a graph. The graph visualizer is a component of TensorBoard that renders the structure of your graph visually in a browser. The easiest way to create a visualization is to pass a tf.Graph when creating the tf.summary.FileWriter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0]])\n",
    "w = tf.Variable(tf.random_uniform([2, 2]))\n",
    "y = tf.matmul(x, w)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  writer = tf.summary.FileWriter(\"./\", sess.graph)\n",
    "  writer.close()\n",
    "    \n",
    "# tensorboard --logdir=/Users/antonmax2/Documents/dev/TensorFlowTutorials/low_level_apis      \n",
    "        # to activate tensorboard in directory\n",
    "# http://localhost:6006/           \n",
    "        # to open in chrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use multiple graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_1 = tf.Graph()\n",
    "with g_1.as_default():\n",
    "  # Operations created in this scope will be added to `g_1`.\n",
    "  c = tf.constant(\"Node in g_1\")\n",
    "\n",
    "  # Sessions created in this scope will run operations from `g_1`.\n",
    "  sess_1 = tf.Session()\n",
    "\n",
    "g_2 = tf.Graph()\n",
    "with g_2.as_default():\n",
    "  # Operations created in this scope will be added to `g_2`.\n",
    "  d = tf.constant(\"Node in g_2\")\n",
    "\n",
    "# Alternatively, you can pass a graph when constructing a <a href=\"../api_docs/python/tf/Session\"><code>tf.Session</code></a>:\n",
    "# `sess_2` will run operations from `g_2`.\n",
    "sess_2 = tf.Session(graph=g_2)\n",
    "\n",
    "assert c.graph is g_1\n",
    "assert sess_1.graph is g_1\n",
    "\n",
    "assert d.graph is g_2\n",
    "assert sess_2.graph is g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
